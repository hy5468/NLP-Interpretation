# NLP-Interpretation
A paper list for interpreting neural networks in natural language processing.

- **[ACL-17]**: What do Neural Machine Translation Models Learn about Morphology? [[paper]](https://www.aclweb.org/anthology/P17-1080.pdf)

- **[NAACL-19]**: Attention is not Explanation. [[paper]](https://www.aclweb.org/anthology/N19-1357.pdf)

- **[ACL-19]**: Is Attention Interpretable? [[paper]](https://www.aclweb.org/anthology/P19-1282.pdf)

- **[ACL-19]**: Assessing the Ability of Self-Attention Networks to Learn Word Order. [[paper]](https://www.aclweb.org/anthology/P19-1354.pdf)

- **[ACL-19]**: BERT Rediscovers the Classical NLP Pipeline. [[paper]](https://www.aclweb.org/anthology/P19-1452.pdf)

- **[ACL-19]**: What does BERT learn about the structure of language? [[paper]](https://www.aclweb.org/anthology/P19-1356.pdf)

- **[ACL-19-workshop]**: What does BERT look at?An Analysis of BERTâ€™s Attention. [[paper]](https://www.aclweb.org/anthology/W19-4828.pdf)

- **[EMNLP-19]**: Attention is not not Explanation. [[paper]](https://www.aclweb.org/anthology/D19-1002.pdf)

- **[EMNLP-19]**: Designing and Interpreting Probes with Control Tasks. [[paper]](https://www.aclweb.org/anthology/D19-1275.pdf)

- **[EMNLP-19]**: Encoders Help You Disambiguate Word Sensesin Neural Machine Translation. [[paper]](https://www.aclweb.org/anthology/D19-1149.pdf)

- **[EMNLP-19]**: The Bottom-up Evolution of Representations in the Transformer:A Study with Machine Translation and Language Modeling Objectives. [[paper]](https://www.aclweb.org/anthology/D19-1448.pdf)
